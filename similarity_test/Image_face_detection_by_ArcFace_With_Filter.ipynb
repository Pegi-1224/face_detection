{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58291653-4dfe-45e8-a971-de9aa282ebdc",
   "metadata": {},
   "source": [
    "# RetinaFace + ArcFace\n",
    "## Improve the accuracy by switching to other pre-trained model\n",
    "With limite of min box size and keep top 3 largest face will get cleaner embeddings which include higher similarity scores and better overall MCC, TPR, and TNR.\n",
    "\n",
    "## Filter Applied in Embedding to ensure Accuracy:\n",
    "1. Number of face restriction\n",
    "2. Face size restriction\n",
    "\n",
    "## Embedding Fallback Strategy Applied:\n",
    "1. Try det_score ≥ 0.9 + size ≥ 80px (strict)\n",
    "2. If none: try det_score ≥ 0.5 + size ≥ 80px\n",
    "3. If none: try det_score ≥ 0.5 + size ≥ 30px\n",
    "4. If none: take highest confidence face regardless of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10cd1a71-8451-4f58-933c-ca881a72f3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peggy\\anaconda3\\envs\\insightface_env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\peggy/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\peggy/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\peggy/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\peggy/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\peggy/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Angelina_Jolie: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angelina_Jolie: 6 detected → 0 strict → 6 fallback → 6 total embeddings (6 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Brad_Pitt: 100%|██████████| 7/7 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brad_Pitt: 8 detected → 1 strict → 6 fallback → 7 total embeddings (6 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chris_Evans: 100%|██████████| 8/8 [00:02<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris_Evans: 16 detected → 0 strict → 8 fallback → 8 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chris_Hemsworth: 100%|██████████| 9/9 [00:02<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris_Hemsworth: 13 detected → 0 strict → 9 fallback → 9 total embeddings (9 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cristiano_Ronaldo: 100%|██████████| 9/9 [00:02<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano_Ronaldo: 10 detected → 0 strict → 9 fallback → 9 total embeddings (9 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dwayne_Johnson: 100%|██████████| 8/8 [00:02<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dwayne_Johnson: 12 detected → 2 strict → 6 fallback → 8 total embeddings (6 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emma_Stone: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma_Stone: 22 detected → 1 strict → 9 fallback → 10 total embeddings (9 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emma_Watson: 100%|██████████| 12/12 [00:03<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma_Watson: 17 detected → 1 strict → 11 fallback → 12 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gal_Gadot: 100%|██████████| 11/11 [00:03<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gal_Gadot: 18 detected → 0 strict → 11 fallback → 11 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hugh_Jackman: 100%|██████████| 11/11 [00:02<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugh_Jackman: 13 detected → 0 strict → 11 fallback → 11 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jennifer_Aniston: 100%|██████████| 8/8 [00:03<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer_Aniston: 17 detected → 2 strict → 6 fallback → 8 total embeddings (6 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jennifer_Lawrence: 100%|██████████| 8/8 [00:02<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer_Lawrence: 12 detected → 0 strict → 8 fallback → 8 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Johnny_Depp: 100%|██████████| 11/11 [00:02<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny_Depp: 13 detected → 1 strict → 10 fallback → 11 total embeddings (10 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Julia_Roberts: 100%|██████████| 11/11 [00:03<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia_Roberts: 16 detected → 2 strict → 9 fallback → 11 total embeddings (9 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keanu_Reeves: 100%|██████████| 11/11 [00:03<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keanu_Reeves: 17 detected → 0 strict → 11 fallback → 11 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leonardo_DiCaprio: 100%|██████████| 8/8 [00:02<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo_DiCaprio: 10 detected → 0 strict → 8 fallback → 8 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Margot_Robbie: 100%|██████████| 11/11 [00:03<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margot_Robbie: 21 detected → 0 strict → 11 fallback → 11 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meryl_Streep: 100%|██████████| 10/10 [00:02<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meryl_Streep: 12 detected → 0 strict → 10 fallback → 10 total embeddings (10 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan_Freeman: 100%|██████████| 10/10 [00:02<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgan_Freeman: 11 detected → 0 strict → 10 fallback → 10 total embeddings (10 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Natalie_Portman: 100%|██████████| 11/11 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natalie_Portman: 13 detected → 1 strict → 10 fallback → 11 total embeddings (10 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rihanna: 100%|██████████| 7/7 [00:01<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rihanna: 8 detected → 0 strict → 7 fallback → 7 total embeddings (7 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Robert_Downey_Jr: 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert_Downey_Jr: 13 detected → 1 strict → 8 fallback → 9 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samuel_L._Jackson: 100%|██████████| 8/8 [00:02<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samuel_L._Jackson: 10 detected → 0 strict → 8 fallback → 8 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scarlett_Johansson: 100%|██████████| 10/10 [00:02<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scarlett_Johansson: 16 detected → 2 strict → 7 fallback → 9 total embeddings (7 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selena_Gomez: 100%|██████████| 13/13 [00:03<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selena_Gomez: 19 detected → 2 strict → 11 fallback → 13 total embeddings (11 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taylor_Swift: 100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor_Swift: 31 detected → 0 strict → 10 fallback → 10 total embeddings (10 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tom_Hanks: 100%|██████████| 6/6 [00:01<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom_Hanks: 8 detected → 1 strict → 5 fallback → 6 total embeddings (5 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will_Smith: 100%|██████████| 9/9 [00:02<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will_Smith: 12 detected → 1 strict → 8 fallback → 9 total embeddings (8 images used fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zendaya: 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zendaya: 13 detected → 0 strict → 10 fallback → 10 total embeddings (10 images used fallback)\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE\n",
      "================================================================================\n",
      "Strict detection threshold: 0.9\n",
      "Fallback detection threshold: 0.5\n",
      "Strict minimum box size: 80px\n",
      "Fallback minimum box size: 30px\n",
      "Top faces per image: 3\n",
      "\n",
      "Total images processed: 273\n",
      "Images with detected faces: 271\n",
      "Images needing fallback strategy: 253 (93.4%)\n",
      "\n",
      "Total faces detected: 407\n",
      "Faces passing strict criteria: 18\n",
      "Faces added via fallback: 253\n",
      "Final embeddings saved: 271\n",
      "Celebrities with valid faces: 29\n",
      "\n",
      "Output saved to: C:\\Users\\peggy\\Desktop\\FaceDetection\\celebrity_face_embeddings_top3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "import pickle\n",
    "\n",
    "# Configuration\n",
    "dataset_path    = r\"C:\\Users\\peggy\\Desktop\\FaceDetection\\celebrities_face\\face\"\n",
    "output_pkl      = r\"C:\\Users\\peggy\\Desktop\\FaceDetection\\celebrity_face_embeddings_top3.pkl\"\n",
    "min_box_size    = 80     # drop faces smaller than 80*80 pixels\n",
    "top_n           = 3      # keep at most 3 largest faces per image\n",
    "det_thresh      = 0.9    # only accept detections with score ≥ 0.90\n",
    "fallback_det_thresh = 0.5  # fallback threshold if no faces pass strict criteria\n",
    "fallback_min_size = 30     # fallback minimum size if no faces pass strict criteria\n",
    "\n",
    "# Initialize model\n",
    "app = FaceAnalysis(name='buffalo_l')\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Process images\n",
    "embedding_output = {}\n",
    "total_faces_detected = 0\n",
    "total_faces_after_strict_filter = 0\n",
    "total_faces_after_fallback = 0\n",
    "total_images_processed = 0\n",
    "total_images_with_faces = 0\n",
    "images_needing_fallback = 0\n",
    "\n",
    "for celeb_name in os.listdir(dataset_path):\n",
    "    celeb_folder = os.path.join(dataset_path, celeb_name)\n",
    "    if not os.path.isdir(celeb_folder):\n",
    "        continue\n",
    "    \n",
    "    all_embs = []\n",
    "    celeb_faces_detected = 0\n",
    "    celeb_faces_strict = 0\n",
    "    celeb_images_fallback = 0\n",
    "    \n",
    "    for img_name in tqdm(os.listdir(celeb_folder), desc=celeb_name):\n",
    "        img_path = os.path.join(celeb_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        total_images_processed += 1\n",
    "        faces = app.get(img)\n",
    "        if not faces:\n",
    "            continue\n",
    "            \n",
    "        total_images_with_faces += 1\n",
    "        celeb_faces_detected += len(faces)\n",
    "        total_faces_detected += len(faces)\n",
    "        \n",
    "        # Strategy 1: Apply strict filters (det_thresh + size)\n",
    "        strict_filtered = []\n",
    "        for f in faces:\n",
    "            if f.det_score >= det_thresh:\n",
    "                x1, y1, x2, y2 = map(int, f.bbox[:4])\n",
    "                w, h = x2-x1, y2-y1\n",
    "                if w >= min_box_size and h >= min_box_size:\n",
    "                    strict_filtered.append((f, w*h))\n",
    "        \n",
    "        selected_faces = []\n",
    "        \n",
    "        if strict_filtered:\n",
    "            # Use strict criteria - sort by area and take top_n\n",
    "            strict_filtered.sort(key=lambda tup: tup[1], reverse=True)\n",
    "            selected_faces = [tup[0] for tup in strict_filtered[:top_n]]\n",
    "            celeb_faces_strict += len(selected_faces)\n",
    "            total_faces_after_strict_filter += len(selected_faces)\n",
    "            \n",
    "        else:\n",
    "            # Fallback strategy: ensure every image contributes at least one face\n",
    "            # Priority 1: Lower detection threshold but keep size requirement\n",
    "            fallback_candidates = []\n",
    "            for f in faces:\n",
    "                if f.det_score >= fallback_det_thresh:\n",
    "                    x1, y1, x2, y2 = map(int, f.bbox[:4])\n",
    "                    w, h = x2-x1, y2-y1\n",
    "                    if w >= min_box_size and h >= min_box_size:\n",
    "                        fallback_candidates.append((f, w*h))\n",
    "            \n",
    "            if fallback_candidates:\n",
    "                # Use lower det_thresh but same size requirement\n",
    "                fallback_candidates.sort(key=lambda tup: tup[1], reverse=True)\n",
    "                selected_faces = [fallback_candidates[0][0]]  # Take only the largest\n",
    "            else:\n",
    "                # Priority 2: Lower both detection threshold and size requirement\n",
    "                fallback_candidates = []\n",
    "                for f in faces:\n",
    "                    if f.det_score >= fallback_det_thresh:\n",
    "                        x1, y1, x2, y2 = map(int, f.bbox[:4])\n",
    "                        w, h = x2-x1, y2-y1\n",
    "                        if w >= fallback_min_size and h >= fallback_min_size:\n",
    "                            fallback_candidates.append((f, w*h, f.det_score))\n",
    "                \n",
    "                if fallback_candidates:\n",
    "                    # Sort by detection score (confidence), then by size\n",
    "                    fallback_candidates.sort(key=lambda tup: (tup[2], tup[1]), reverse=True)\n",
    "                    selected_faces = [fallback_candidates[0][0]]  # Take highest confidence\n",
    "                else:\n",
    "                    # Last resort: take the most confident face regardless of size\n",
    "                    best_face = max(faces, key=lambda f: f.det_score)\n",
    "                    selected_faces = [best_face]\n",
    "            \n",
    "            celeb_images_fallback += 1\n",
    "            images_needing_fallback += 1\n",
    "            total_faces_after_fallback += len(selected_faces)\n",
    "        \n",
    "        # Collect embeddings from selected faces\n",
    "        for face in selected_faces:\n",
    "            all_embs.append(face.normed_embedding)\n",
    "    \n",
    "    if all_embs:\n",
    "        embedding_output[celeb_name] = np.stack(all_embs)\n",
    "        \n",
    "    # Print stats for this celebrity\n",
    "    strict_embs = celeb_faces_strict\n",
    "    fallback_embs = len(all_embs) - celeb_faces_strict\n",
    "    print(f\"{celeb_name}: {celeb_faces_detected} detected → {strict_embs} strict → {fallback_embs} fallback → {len(all_embs)} total embeddings ({celeb_images_fallback} images used fallback)\")\n",
    "\n",
    "# Save embedded data\n",
    "with open(output_pkl, \"wb\") as f:\n",
    "    pickle.dump(embedding_output, f)\n",
    "\n",
    "# Print final statistics\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"PROCESSING COMPLETE\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Strict detection threshold: {det_thresh}\")\n",
    "print(f\"Fallback detection threshold: {fallback_det_thresh}\")\n",
    "print(f\"Strict minimum box size: {min_box_size}px\")\n",
    "print(f\"Fallback minimum box size: {fallback_min_size}px\")\n",
    "print(f\"Top faces per image: {top_n}\")\n",
    "print(f\"\")\n",
    "print(f\"Total images processed: {total_images_processed}\")\n",
    "print(f\"Images with detected faces: {total_images_with_faces}\")\n",
    "print(f\"Images needing fallback strategy: {images_needing_fallback} ({images_needing_fallback/total_images_with_faces*100:.1f}%)\")\n",
    "print(f\"\")\n",
    "print(f\"Total faces detected: {total_faces_detected}\")\n",
    "print(f\"Faces passing strict criteria: {total_faces_after_strict_filter}\")\n",
    "print(f\"Faces added via fallback: {total_faces_after_fallback}\")\n",
    "print(f\"Final embeddings saved: {sum(len(embs) for embs in embedding_output.values())}\")\n",
    "print(f\"Celebrities with valid faces: {len(embedding_output)}\")\n",
    "print(f\"\")\n",
    "print(f\"Output saved to: {output_pkl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108e0ff-6766-400e-a54a-19f64e8bd929",
   "metadata": {},
   "source": [
    "# Cosine Similarity comparison - find the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "650ac98e-3e96-4c08-a9f5-939c0f6a61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"C:\\Users\\peggy\\Desktop\\FaceDetection\\celebrity_face_embeddings_top3.pkl\", \"rb\") as f:\n",
    "    embeddings_dict = pickle.load(f)\n",
    "\n",
    "# Flatten to list of (label, embedding)\n",
    "data = []\n",
    "for label, embeddings in embeddings_dict.items():\n",
    "    for emb in embeddings:\n",
    "        data.append((label, emb))\n",
    "\n",
    "labels, vectors = zip(*data)\n",
    "labels = np.array(labels)\n",
    "vectors = np.stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "523b785a-6a00-4fba-b757-cd03fe098496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold by MCC: 0.3122\n",
      "MCC = 0.9041\n",
      "TPR (Recall) = 0.8390, TNR (Specificity) = 0.9994\n",
      "Confusion matrix: TP=1970, FP=40, FN=378, TN=70782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "def find_matches(embedding, all_embeddings, threshold):\n",
    "    sims = cosine_similarity([embedding], all_embeddings)[0]\n",
    "    return sims >= threshold\n",
    "\n",
    "def evaluate_threshold(threshold, vectors, labels):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(len(vectors)):\n",
    "        anchor = vectors[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        # Predict similar identities\n",
    "        pred_mask = find_matches(anchor, vectors, threshold)\n",
    "\n",
    "        # Ground truth: which embeddings belong to the same label\n",
    "        true_mask = labels == label\n",
    "\n",
    "        for j in range(len(vectors)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            pred = pred_mask[j]\n",
    "            truth = true_mask[j]\n",
    "\n",
    "            if pred and truth:\n",
    "                TP += 1\n",
    "            elif pred and not truth:\n",
    "                FP += 1\n",
    "            elif not pred and truth:\n",
    "                FN += 1\n",
    "            elif not pred and not truth:\n",
    "                TN += 1\n",
    "\n",
    "    mcc = matthews_corrcoef(\n",
    "        [1]*TP + [1]*FP + [0]*FN + [0]*TN,\n",
    "        [1]*TP + [0]*FP + [1]*FN + [0]*TN\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"threshold\": threshold,\n",
    "        \"TP\": TP, \"FP\": FP, \"FN\": FN, \"TN\": TN,\n",
    "        \"TPR\": TP / (TP + FN) if TP + FN > 0 else 0,\n",
    "        \"TNR\": TN / (TN + FP) if TN + FP > 0 else 0,\n",
    "        \"MCC\": mcc,\n",
    "    }\n",
    "\n",
    "best_result = None\n",
    "for t in np.linspace(0.1, 0.9, 50):\n",
    "    result = evaluate_threshold(t, vectors, labels)\n",
    "    if best_result is None or result[\"MCC\"] > best_result[\"MCC\"]:\n",
    "        best_result = result\n",
    "\n",
    "# Print result\n",
    "print(f\"Best threshold by MCC: {best_result['threshold']:.4f}\")\n",
    "print(f\"MCC = {best_result['MCC']:.4f}\")\n",
    "print(f\"TPR (Recall) = {best_result['TPR']:.4f}, TNR (Specificity) = {best_result['TNR']:.4f}\")\n",
    "print(f\"Confusion matrix: TP={best_result['TP']}, FP={best_result['FP']}, FN={best_result['FN']}, TN={best_result['TN']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc79bd1-ac8e-45b1-be89-3a7a34542745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
